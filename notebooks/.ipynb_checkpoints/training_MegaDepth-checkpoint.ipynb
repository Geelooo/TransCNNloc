{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook shows how to run the inference in the training-time two-view settings on the validation or training set of MegaDepth to visualize the training metrics and losses.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from pixloc import run_Aachen\n",
    "from pixloc.pixlib.datasets.megadepth import MegaDepth\n",
    "from pixloc.pixlib.utils.tensor import batch_to_device, map_tensor\n",
    "from pixloc.pixlib.utils.tools import set_seed\n",
    "from pixloc.pixlib.utils.experiments import load_experiment\n",
    "from pixloc.visualization.viz_2d import (\n",
    "    plot_images, plot_keypoints, plot_matches, cm_RdGn,\n",
    "    features_to_RGB, add_text)\n",
    "\n",
    "torch.set_grad_enabled(False);\n",
    "mpl.rcParams['image.interpolation'] = 'bilinear'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a validation or training dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.base_dataset INFO] Creating dataset MegaDepth\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth INFO] Sampling new images or pairs with seed 1\n",
      "  0%|                                                                                                                                                               | 0/77 [00:00<?, ?it/s][08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0016 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0033 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0034 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0041 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0044 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0047 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0049 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0058 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0062 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0064 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0067 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0071 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0076 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0078 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0090 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0094 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0099 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0102 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0121 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0129 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0133 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0141 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0151 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0162 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0168 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0175 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0177 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0178 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0181 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0185 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0186 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0197 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0204 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0205 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0209 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0212 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0217 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0223 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0229 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0231 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0238 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0252 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0257 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0271 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0275 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0277 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0281 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0285 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0286 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0290 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0294 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0303 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0306 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0307 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0323 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0349 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0360 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0387 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0389 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0402 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0406 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0412 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0443 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0482 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 0768 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 1001 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 3346 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 5000 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 5001 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 5002 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 5003 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 5008 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 5011 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 5014 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 5015 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 5016 does not have an info file\n",
      "[08/03/2022 11:18:40 pixloc.pixlib.datasets.megadepth WARNING] Scene 5018 does not have an info file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 77/77 [00:00<00:00, 1504.38it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m conf \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_overlap\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.4\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_overlap\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1.0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_workers\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     20\u001b[0m }\n\u001b[0;32m---> 21\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[43mMegaDepth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m orig_items \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mitems\n",
      "File \u001b[0;32m~/Workplace/python/pixloc/pixloc/pixlib/datasets/base_dataset.py:162\u001b[0m, in \u001b[0;36mBaseDataset.get_data_loader\u001b[0;34m(self, split, shuffle, pinned, distributed)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m         shuffle \u001b[38;5;241m=\u001b[39m (split \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconf\u001b[38;5;241m.\u001b[39mshuffle_training)\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpinned\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworker_init_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworker_init_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pixloc/lib/python3.8/site-packages/torch/utils/data/dataloader.py:277\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 277\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pixloc/lib/python3.8/site-packages/torch/utils/data/sampler.py:97\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement))\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue, but got num_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples))\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "conf = {\n",
    "    'min_overlap': 0.4,\n",
    "    'max_overlap': 1.0,\n",
    "    'max_num_points3D': 512,\n",
    "    'force_num_points3D': True,\n",
    "    \n",
    "    'resize': 512,\n",
    "    'resize_by': 'min',\n",
    "    'crop': 512,\n",
    "    'optimal_crop': True,\n",
    "    \n",
    "    'init_pose': [0.75, 1.],\n",
    "#     'init_pose': 'max_error',\n",
    "#     'init_pose_max_error': 4,\n",
    "#     'init_pose_num_samples': 50,\n",
    "    \n",
    "    'batch_size': 1,\n",
    "    'seed': 1,\n",
    "    'num_workers': 0,\n",
    "}\n",
    "loader = MegaDepth(conf).get_data_loader('val', shuffle=True)\n",
    "orig_items = loader.dataset.items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the training experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the example experiment. Replace with your own training experiment.\n",
    "exp = run_Aachen.experiment\n",
    "device = 'cuda'\n",
    "conf = {\n",
    "    'optimizer': {'num_iters': 20,},\n",
    "}\n",
    "refiner = load_experiment(exp, conf).to(device)\n",
    "print(OmegaConf.to_yaml(refiner.conf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run on a few examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reference image: red/green = reprojections of 3D points not/visible in the query at the ground truth pose\n",
    "- Query image: red/blue/green = reprojections of 3D points at the initial/final/GT poses\n",
    "- ΔP/ΔR/Δt are final errors in terms of 2D reprojections, rotation, and translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(7)\n",
    "for _, data in zip(range(5), loader):\n",
    "    data_ = batch_to_device(data, device)\n",
    "    pred_ = refiner(data_)\n",
    "    pred = map_tensor(pred_, lambda x: x[0].cpu())\n",
    "    data = map_tensor(data, lambda x: x[0].cpu())\n",
    "    cam_q = data['query']['camera']\n",
    "    p3D_r = data['ref']['points3D']\n",
    "        \n",
    "    p2D_r, valid_r = data['ref']['camera'].world2image(p3D_r)\n",
    "    p2D_q_gt, valid_q = cam_q.world2image(data['T_r2q_gt'] * p3D_r)\n",
    "    p2D_q_init, _ = cam_q.world2image(data['T_r2q_init'] * p3D_r)\n",
    "    p2D_q_opt, _ = cam_q.world2image(pred['T_r2q_opt'][-1] * p3D_r)\n",
    "    valid = valid_q & valid_r\n",
    "    \n",
    "    losses = refiner.loss(pred_, data_)\n",
    "    mets = refiner.metrics(pred_, data_)\n",
    "    errP = f\"ΔP {losses['reprojection_error/init'].item():.2f} -> {losses['reprojection_error'].item():.3f} px; \"\n",
    "    errR = f\"ΔR {mets['R_error/init'].item():.2f} -> {mets['R_error'].item():.3f} deg; \"\n",
    "    errt = f\"Δt {mets['t_error/init'].item():.2f} -> {mets['t_error'].item():.3f} %m\"\n",
    "    print(errP, errR, errt)\n",
    "\n",
    "    imr, imq = data['ref']['image'].permute(1, 2, 0), data['query']['image'].permute(1, 2, 0)\n",
    "    plot_images([imr, imq],titles=[(data['scene'][0], valid_r.sum().item(), valid_q.sum().item()), errP+'; '+errR])\n",
    "    plot_keypoints([p2D_r[valid_r], p2D_q_gt[valid]], colors=[cm_RdGn(valid[valid_r]), 'lime'])\n",
    "    plot_keypoints([np.empty((0, 2)), p2D_q_init[valid]], colors='red')\n",
    "    plot_keypoints([np.empty((0, 2)), p2D_q_opt[valid]], colors='blue')\n",
    "    add_text(0, 'reference')\n",
    "    add_text(1, 'query')\n",
    "\n",
    "    continue\n",
    "    for i, (F0, F1) in enumerate(zip(pred['ref']['feature_maps'], pred['query']['feature_maps'])):\n",
    "        C_r, C_q = pred['ref']['confidences'][i][0], pred['query']['confidences'][i][0]\n",
    "        plot_images([C_r, C_q], cmaps=mpl.cm.turbo)\n",
    "        add_text(0, f'Level {i}')\n",
    "            \n",
    "        axes = plt.gcf().axes\n",
    "        axes[0].imshow(imr, alpha=0.2, extent=axes[0].images[0]._extent)\n",
    "        axes[1].imshow(imq, alpha=0.2, extent=axes[1].images[0]._extent)\n",
    "        plot_images(features_to_RGB(F0.numpy(), F1.numpy(), skip=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
